{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atividade de implementação e teste do Perceptron - Questão 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nome:** Dimitri Leandro de Oliveira Silva\n",
    "\n",
    "**RA:** 11201720576"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enunciado:\n",
    "\n",
    "1) Utilizando o algoritmo do perceptron, realize testes com os dados fornecidos nos arquivos dataset1.txt a dataset6.txt. Comente os resultados obtidos, incluindo observações sobre: Influência do passo de adaptação, Convergência do algoritmo, Critério de Parada (e se foi necessário alterá-lo). Para ajudar, ilustre com gráficos da evolução dos pesos do perceptron (valor do peso x # iteração)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sobre as Implementações"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em primeiro lugar, implementou-se uma classe chamada **Neuron**. Essa é a classe que contém todo o algoritmo do Perceptron, responsável por receber um conjunto de dados e atualizar os pesos referentes a cada entrada, incluindo o bias, por várias épocas até que o critério de parada seja atingido. A função de ativação utilizada foi o degrau unitário, isto é, o neurônio só é ativado caso a entrada líquida seja maior que 0.\n",
    "\n",
    "Entretanto, essa classe possui o problema da classificação binária, ou seja, o algoritmo implementado só consegue classificar datasets que contenham apenas duas classes. Para solucionar esse problema, implementou-se a classe **MultiNeuron**. Essa classe instancia um objeto da classe **Neuron** para cada classe do dataset, ainda que seja um dataset binário.\n",
    "\n",
    "A princípio, só seria necessário utilizar **Qtd de Classes - 1** neurônios, assim, as primeiras classes teriam o seu próprio neurônio, exceto a última, que só seria escolhida caso nenhum dos outros neurônios fosse ativado. Todavia, em diversos testes previamente realizados, observou-se dois pontos importantes: 1) as vezes mais de um neurônio era ativado ao mesmo tempo para classificar uma única amostra; 2) Um dado pertencente à última classe (a que não possui um neurônio) estaria suscetível ao erro de todos os outros neurônios antes de finalmente ser atribuído à classe correta. Por esses dois motivos, desejou-se implementar a classe **MultiNeuron** de forma que todas as classes recebessem um neurônio. Assim, a última classe não seria tão injustiçada.\n",
    "\n",
    "Nos casos de empate, isto é, caso mais de um neurônio for ativado ao mesmo tempo para uma mesma amostra, é escolhido aquele com a maior entrada líquida. Três critérios de parada foram definidos. Um neurônio só interrompe seu treinamento caso: 1) a acurácia de treinamento tenha atingido 100% (convergência); 2) o número de épocas tiver chegado no limite determinado; 3) a acurácia de treinamento não tiver melhorado nas últimas **J** iterações, sendo __J__ equivalente a um percentual do limite de épocas determinado no item 2.\n",
    "\n",
    "Os únicos pacotes utilizados durante as implementações foram: Numpy, Random e Joblib."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando os pacotes necessários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "\n",
    "sys.path.append(\"/home/dimi/Programming/MachineLearningUFABC/Projeto_Perceptron_Adaline/Perceptron/python/\")\n",
    "from MultiNeuronClass import MultiNeuron\n",
    "\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definindo algumas funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plotarDataset(dataframe, nome):\n",
    "    \n",
    "    %matplotlib inline\n",
    "    %config InlineBackend.figure_format = 'svg'\n",
    "    params = {'figure.figsize': [10, 5], \n",
    "              'figure.titlesize': 16,\n",
    "              'axes.labelsize': 12,\n",
    "              'axes.titlesize':14, \n",
    "              'font.size': 12,\n",
    "              'legend.fontsize': 12, \n",
    "              'xtick.labelsize': 10, \n",
    "              'ytick.labelsize': 10\n",
    "             }\n",
    "    plt.rcParams.update(params)\n",
    "    \n",
    "    plt.scatter(dataframe[\"feature1\"], dataframe[\"feature2\"], c=dataframe[\"classe\"], s=300, alpha=0.75)\n",
    "    plt.title(nome)\n",
    "    plt.xlabel(\"Feature 1\")\n",
    "    plt.ylabel(\"Feature 2\")\n",
    "    plt.grid(True, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plotarResultadoTreinamento(arrayValoresTaxaAprendizagem, arrayObjMultiNeuron):\n",
    "    colunas = [\"Taxa de Aprendizagem\", \"Neurônio\", \"Total de Épocas\", \"Acurácia de Treinamento\", \"Critério de Parada\"]\n",
    "    data    = []\n",
    "\n",
    "    for i, taxaAtual in enumerate(arrayValoresTaxaAprendizagem):    \n",
    "        for j, neuronioAtual in enumerate(arrayObjMultiNeuron[i].arrayNeuronios):\n",
    "            linha = [taxaAtual, j+1, neuronioAtual.qtdIteracoes, max(neuronioAtual.evolucaoAcuracias), neuronioAtual.motivoParada]\n",
    "            data.append(linha)\n",
    "\n",
    "    return pd.DataFrame(data=data, columns=colunas).style.hide_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plotarEvolucaoAcuracias(arrayValoresTaxaAprendizagem, arrayObjMultiNeuron):\n",
    "    \n",
    "    %matplotlib inline\n",
    "    %config InlineBackend.figure_format = 'svg'\n",
    "    params = {'figure.figsize': [12, 2.5], \n",
    "              'figure.titlesize': 10,\n",
    "              'axes.labelsize': 6,\n",
    "              'axes.titlesize':8, \n",
    "              'font.size': 8,\n",
    "              'legend.fontsize': 6, \n",
    "              'xtick.labelsize': 4, \n",
    "              'ytick.labelsize': 4\n",
    "             }\n",
    "    plt.rcParams.update(params)\n",
    "    \n",
    "    for i, taxaAtual in enumerate(arrayValoresTaxaAprendizagem):\n",
    "    \n",
    "        fig, axs = plt.subplots(1, len(arrayObjMultiNeuron[i].arrayNeuronios))\n",
    "\n",
    "        for j, neuronioAtual in enumerate(arrayObjMultiNeuron[i].arrayNeuronios):\n",
    "\n",
    "            axs[j].plot(neuronioAtual.evolucaoAcuracias)\n",
    "            axs[j].set_title(\"Neurônio \" + str(j+1))\n",
    "            axs[j].set_xlabel(\"Época\")\n",
    "            axs[j].set_ylabel(\"Acurácia\")\n",
    "            axs[j].set_ylim(0, 1)\n",
    "            axs[j].grid(alpha=0.5)\n",
    "\n",
    "        fig.suptitle('Taxa de Aprendizagem: ' + str(taxaAtual))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plotarEvolucaoPesos(arrayValoresTaxaAprendizagem, arrayObjMultiNeuron):\n",
    "    \n",
    "    %matplotlib inline\n",
    "    %config InlineBackend.figure_format = 'svg'\n",
    "    params = {'figure.figsize': [12, 2.5], \n",
    "              'figure.titlesize': 10,\n",
    "              'axes.labelsize': 6,\n",
    "              'axes.titlesize':8, \n",
    "              'font.size': 8,\n",
    "              'legend.fontsize': 6, \n",
    "              'xtick.labelsize': 4, \n",
    "              'ytick.labelsize': 4\n",
    "             }\n",
    "    plt.rcParams.update(params)\n",
    "    \n",
    "    for i, taxaAtual in enumerate(arrayValoresTaxaAprendizagem):\n",
    "    \n",
    "        fig, axs = plt.subplots(1, len(arrayObjMultiNeuron[i].arrayNeuronios))\n",
    "\n",
    "        for j, neuronioAtual in enumerate(arrayObjMultiNeuron[i].arrayNeuronios):\n",
    "\n",
    "            for k, evolucaoPesoAtual in enumerate(neuronioAtual.evolucaoPesos):\n",
    "                axs[j].plot(evolucaoPesoAtual, label=\"Peso \" + str(k+1))\n",
    "            \n",
    "            axs[j].set_title(\"Neurônio \" + str(j+1))\n",
    "            axs[j].set_xlabel(\"Época\")\n",
    "            axs[j].set_ylabel(\"Valor\")\n",
    "            axs[j].grid(alpha=0.5)\n",
    "            axs[j].legend()\n",
    "\n",
    "        fig.suptitle('Taxa de Aprendizagem: ' + str(taxaAtual))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotarACCxTaxa(arrayValoresTaxaAprendizagem, matrizAcuracias):\n",
    "    %matplotlib inline\n",
    "    %config InlineBackend.figure_format = 'svg'\n",
    "    params = {'figure.figsize': [10, 5], \n",
    "              'figure.titlesize': 16,\n",
    "              'axes.labelsize': 12,\n",
    "              'axes.titlesize':14, \n",
    "              'font.size': 12,\n",
    "              'legend.fontsize': 12, \n",
    "              'xtick.labelsize': 10, \n",
    "              'ytick.labelsize': 10\n",
    "             }\n",
    "    plt.rcParams.update(params)\n",
    "\n",
    "    mediasAcuraciasCadaTaxa   = [np.mean(acuraciasTaxaAtual) for acuraciasTaxaAtual in matrizAcuracias]\n",
    "    desvPadsAcuraciasCadaTaxa = [np.std(acuraciasTaxaAtual) for acuraciasTaxaAtual in matrizAcuracias]\n",
    "\n",
    "    plt.errorbar(arrayValoresTaxaAprendizagem, mediasAcuraciasCadaTaxa, yerr=desvPadsAcuraciasCadaTaxa, capsize=3)\n",
    "    plt.xscale(\"log\")\n",
    "    plt.title(\"Acurácia média de teste e desvio padrão\")\n",
    "    plt.xlabel(\"Taxa de Aprendizagem\")\n",
    "    plt.ylabel(\"Acurácia\")\n",
    "    plt.grid(alpha=0.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando os datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "colunas  = [\"feature1\", \"feature2\", \"classe\"]\n",
    "\n",
    "dataset1 = pd.read_csv(\"/home/dimi/Programming/MachineLearningUFABC/Projeto_Perceptron_Adaline/Datasets/dataset1.txt\", names=colunas, sep=' ', header=None)\n",
    "dataset2 = pd.read_csv(\"/home/dimi/Programming/MachineLearningUFABC/Projeto_Perceptron_Adaline/Datasets/dataset2.txt\", names=colunas, sep=' ', header=None)\n",
    "dataset3 = pd.read_csv(\"/home/dimi/Programming/MachineLearningUFABC/Projeto_Perceptron_Adaline/Datasets/dataset3.txt\", names=colunas, sep=' ', header=None)\n",
    "dataset4 = pd.read_csv(\"/home/dimi/Programming/MachineLearningUFABC/Projeto_Perceptron_Adaline/Datasets/dataset4.txt\", names=colunas, sep=' ', header=None)\n",
    "dataset5 = pd.read_csv(\"/home/dimi/Programming/MachineLearningUFABC/Projeto_Perceptron_Adaline/Datasets/dataset5.txt\", names=colunas, sep=' ', header=None)\n",
    "dataset6 = pd.read_csv(\"/home/dimi/Programming/MachineLearningUFABC/Projeto_Perceptron_Adaline/Datasets/dataset6.txt\", names=colunas, sep=' ', header=None)\n",
    "\n",
    "datasets = [dataset1, dataset2, dataset3, dataset4, dataset5, dataset6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corrigindo os datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os datasets contém as classes 1, 2, 3... Elas não começam em 0, e isso é um problema pra implementação própria. Então só é preciso fazer com que a classe 1 se torne classe 0, classe 2 se torne classe 1 e assim por diante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, datasetAtual in enumerate(datasets):\n",
    "    for j, classeAtual in enumerate(datasetAtual[\"classe\"]):\n",
    "        datasets[i][\"classe\"][j] = classeAtual - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisando a evolução dos neurônios durante o treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nessa seção, os datasets de 1 a 6 serão utilizados para avaliar a evolução dos neurônios durante a etapa de treinamento. Para diversos valores de **taxa de aprendizagem**, serão exibidos: 1) critério de parada de cada neurônio; 2) acurácia de treinamento; 3) quantidade de épocas de treinamento; 4) evolução dos pesos em função das épocas; 5) evolução das acurácias de treinamento em função das épocas. Em todos os casos, **todos** os dados foram utilziados no treinamento. Testes com validação cruzada serão efetuados mais adiante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "datasetAtual = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plotarDataset(datasets[datasetAtual-1], \"Dataset \" + str(datasetAtual))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por possuir duas classes, dois neurônios serão utilizados. Espera-se que uma acurácia de 100% seja atingida. Afinal, a imagem acima mostra claramente que o dataset é linearmente separável."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treinamento com todos os dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A célula abaixo instancia um objeto da classe **MultiNeuron** e faz o treinamento com todos os dados disponíveis no dataset para diversos valores de **taxa de aprendizagem**. É possível definir a quantidade máxima permitida de épocas de treinamento caso se deseje. Esse valor foi fixado em 1000 iterações. Também é possível determinar o percentual da quantidade máxima de épocas que deve ser considerado para parar o treinamento caso a acurácia não melhore nesse percentual de iterações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# QUANTIDADE MAXIMA DE EPOCAS DE TREINAMENTO\n",
    "qtdMaxEpocas         = 1000\n",
    "percentualSemMelhora = 0.35\n",
    "\n",
    "# PEGO OS DADOS DO DATASET COMO ARRAYS E NAO PANDAS\n",
    "x = datasets[datasetAtual-1][[\"feature1\", \"feature2\"]].values\n",
    "y = datasets[datasetAtual-1][\"classe\"].values\n",
    "\n",
    "# DEFININDO O RANGE DA TAXA DE APRENDIZAGEM\n",
    "arrayValoresTaxaAprendizagem = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e-0]\n",
    "\n",
    "# ARRAY PARA GUARDAR OS OBJETOS MULTINEURON DE CADA TAXA DE APRENDIZAGEM\n",
    "arrayObjMultiNeuron = []\n",
    "\n",
    "# PARA CADA VALOR DA TAXA DE APRENDIZAGEM\n",
    "for taxaAtual in arrayValoresTaxaAprendizagem:\n",
    "    objMultiNeuron = MultiNeuron(taxaAprendizagem=taxaAtual, qtdMaxEpocas=qtdMaxEpocas, percentualSemMelhora=percentualSemMelhora, armazenarEvolucaoNeuronios=True)\n",
    "    objMultiNeuron.treinar(x, y)\n",
    "    arrayObjMultiNeuron.append(objMultiNeuron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Critério de parada de cada neurônio para cada taxa de aprendizagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "resultado = plotarResultadoTreinamento(arrayValoresTaxaAprendizagem, arrayObjMultiNeuron)\n",
    "resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifica-se que todos neurônios de todas as taxas de aprendizagem convergiram para 100% em pouquíssimas épocas, como esperado. Essa comportamento só é possível em datasets que sejam linearmente separáveis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evolução das acurácias de treinamento e dos pesos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como o algoritmo convergiu muito rapidamente, a evolução da acurácia de treinamento será mostrada apenas nos datasets seguintes, bem como a evolução dos pesos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "datasetAtual = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plotarDataset(datasets[datasetAtual-1], \"Dataset \" + str(datasetAtual))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dessa vez, percebe-se visualmente que o dataset não é linearmente separável. As acurácias deverão ficar um pouco abaixo de 100%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treinamento com todos os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# QUANTIDADE MAXIMA DE EPOCAS DE TREINAMENTO\n",
    "qtdMaxEpocas = 1000\n",
    "percentualSemMelhora = 0.35\n",
    "\n",
    "# PEGO OS DADOS DO DATASET COMO ARRAYS E NAO PANDAS\n",
    "x = datasets[datasetAtual-1][[\"feature1\", \"feature2\"]].values\n",
    "y = datasets[datasetAtual-1][\"classe\"].values\n",
    "\n",
    "# DEFININDO O RANGE DA TAXA DE APRENDIZAGEM\n",
    "arrayValoresTaxaAprendizagem = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e-0]\n",
    "\n",
    "# ARRAY PARA GUARDAR OS OBJETOS MULTINEURON DE CADA TAXA DE APRENDIZAGEM\n",
    "arrayObjMultiNeuron = []\n",
    "\n",
    "# PARA CADA VALOR DA TAXA DE APRENDIZAGEM\n",
    "for taxaAtual in arrayValoresTaxaAprendizagem:\n",
    "    objMultiNeuron = MultiNeuron(taxaAprendizagem=taxaAtual, qtdMaxEpocas=qtdMaxEpocas, percentualSemMelhora=percentualSemMelhora, armazenarEvolucaoNeuronios=True)\n",
    "    objMultiNeuron.treinar(x, y)\n",
    "    arrayObjMultiNeuron.append(objMultiNeuron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Critério de parada de cada neurônio para cada taxa de aprendizagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "resultado = plotarResultadoTreinamento(arrayValoresTaxaAprendizagem, arrayObjMultiNeuron)\n",
    "resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como esperado, nenhum neurônio conseguiu separar completamente a classe atribuida para si. Aparentemente os casos com taxa de aprendizagem de 1e-3 e 1e-2 foram os que obtiveram as melhores acurácias. \n",
    "\n",
    "Diferetnemente do dataset anterior, o critério de parada mais acionado nesse caso foi o do percentual do máximo de épocas atingido sem qualquer melhoria na acurácia de treinamento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evolução das acurácias de treinamento e dos pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plotarEvolucaoAcuracias(arrayValoresTaxaAprendizagem, arrayObjMultiNeuron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotarEvolucaoPesos(arrayValoresTaxaAprendizagem, arrayObjMultiNeuron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "datasetAtual = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plotarDataset(datasets[datasetAtual-1], \"Dataset \" + str(datasetAtual))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treinamento com todos os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# QUANTIDADE MAXIMA DE EPOCAS DE TREINAMENTO\n",
    "qtdMaxEpocas = 1000\n",
    "percentualSemMelhora = 0.35\n",
    "\n",
    "# PEGO OS DADOS DO DATASET COMO ARRAYS E NAO PANDAS\n",
    "x = datasets[datasetAtual-1][[\"feature1\", \"feature2\"]].values\n",
    "y = datasets[datasetAtual-1][\"classe\"].values\n",
    "\n",
    "# DEFININDO O RANGE DA TAXA DE APRENDIZAGEM\n",
    "arrayValoresTaxaAprendizagem = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e-0]\n",
    "\n",
    "# ARRAY PARA GUARDAR OS OBJETOS MULTINEURON DE CADA TAXA DE APRENDIZAGEM\n",
    "arrayObjMultiNeuron = []\n",
    "\n",
    "# PARA CADA VALOR DA TAXA DE APRENDIZAGEM\n",
    "for taxaAtual in arrayValoresTaxaAprendizagem:\n",
    "    objMultiNeuron = MultiNeuron(taxaAprendizagem=taxaAtual, qtdMaxEpocas=qtdMaxEpocas, percentualSemMelhora=percentualSemMelhora, armazenarEvolucaoNeuronios=True)\n",
    "    objMultiNeuron.treinar(x, y)\n",
    "    arrayObjMultiNeuron.append(objMultiNeuron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Critério de parada de cada neurônio para cada taxa de aprendizagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "resultado = plotarResultadoTreinamento(arrayValoresTaxaAprendizagem, arrayObjMultiNeuron)\n",
    "resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evolução das acurácias de treinamento e dos pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotarEvolucaoAcuracias(arrayValoresTaxaAprendizagem, arrayObjMultiNeuron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plotarEvolucaoPesos(arrayValoresTaxaAprendizagem, arrayObjMultiNeuron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "datasetAtual = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plotarDataset(datasets[datasetAtual-1], \"Dataset \" + str(datasetAtual))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treinamento com todos os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# QUANTIDADE MAXIMA DE EPOCAS DE TREINAMENTO\n",
    "qtdMaxEpocas = 1000\n",
    "percentualSemMelhora = 0.35\n",
    "\n",
    "# PEGO OS DADOS DO DATASET COMO ARRAYS E NAO PANDAS\n",
    "x = datasets[datasetAtual-1][[\"feature1\", \"feature2\"]].values\n",
    "y = datasets[datasetAtual-1][\"classe\"].values\n",
    "\n",
    "# DEFININDO O RANGE DA TAXA DE APRENDIZAGEM\n",
    "arrayValoresTaxaAprendizagem = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e-0]\n",
    "\n",
    "# ARRAY PARA GUARDAR OS OBJETOS MULTINEURON DE CADA TAXA DE APRENDIZAGEM\n",
    "arrayObjMultiNeuron = []\n",
    "\n",
    "# PARA CADA VALOR DA TAXA DE APRENDIZAGEM\n",
    "for taxaAtual in arrayValoresTaxaAprendizagem:\n",
    "    objMultiNeuron = MultiNeuron(taxaAprendizagem=taxaAtual, qtdMaxEpocas=qtdMaxEpocas, percentualSemMelhora=percentualSemMelhora, armazenarEvolucaoNeuronios=True)\n",
    "    objMultiNeuron.treinar(x, y)\n",
    "    arrayObjMultiNeuron.append(objMultiNeuron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Critério de parada de cada neurônio para cada taxa de aprendizagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "resultado = plotarResultadoTreinamento(arrayValoresTaxaAprendizagem, arrayObjMultiNeuron)\n",
    "resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evolução das acurácias de treinamento e dos pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotarEvolucaoAcuracias(arrayValoresTaxaAprendizagem, arrayObjMultiNeuron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plotarEvolucaoPesos(arrayValoresTaxaAprendizagem, arrayObjMultiNeuron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "datasetAtual = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plotarDataset(datasets[datasetAtual-1], \"Dataset \" + str(datasetAtual))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treinamento com todos os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# QUANTIDADE MAXIMA DE EPOCAS DE TREINAMENTO\n",
    "qtdMaxEpocas = 1000\n",
    "percentualSemMelhora = 0.35\n",
    "\n",
    "# PEGO OS DADOS DO DATASET COMO ARRAYS E NAO PANDAS\n",
    "x = datasets[datasetAtual-1][[\"feature1\", \"feature2\"]].values\n",
    "y = datasets[datasetAtual-1][\"classe\"].values\n",
    "\n",
    "# DEFININDO O RANGE DA TAXA DE APRENDIZAGEM\n",
    "arrayValoresTaxaAprendizagem = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e-0]\n",
    "\n",
    "# ARRAY PARA GUARDAR OS OBJETOS MULTINEURON DE CADA TAXA DE APRENDIZAGEM\n",
    "arrayObjMultiNeuron = []\n",
    "\n",
    "# PARA CADA VALOR DA TAXA DE APRENDIZAGEM\n",
    "for taxaAtual in arrayValoresTaxaAprendizagem:\n",
    "    objMultiNeuron = MultiNeuron(taxaAprendizagem=taxaAtual, qtdMaxEpocas=qtdMaxEpocas, percentualSemMelhora=percentualSemMelhora, armazenarEvolucaoNeuronios=True)\n",
    "    objMultiNeuron.treinar(x, y)\n",
    "    arrayObjMultiNeuron.append(objMultiNeuron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Critério de parada de cada neurônio para cada taxa de aprendizagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "resultado = plotarResultadoTreinamento(arrayValoresTaxaAprendizagem, arrayObjMultiNeuron)\n",
    "resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evolução das acurácias de treinamento e dos pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotarEvolucaoAcuracias(arrayValoresTaxaAprendizagem, arrayObjMultiNeuron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plotarEvolucaoPesos(arrayValoresTaxaAprendizagem, arrayObjMultiNeuron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "datasetAtual = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plotarDataset(datasets[datasetAtual-1], \"Dataset \" + str(datasetAtual))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treinamento com todos os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# QUANTIDADE MAXIMA DE EPOCAS DE TREINAMENTO\n",
    "qtdMaxEpocas = 1000\n",
    "percentualSemMelhora = 0.35\n",
    "\n",
    "# PEGO OS DADOS DO DATASET COMO ARRAYS E NAO PANDAS\n",
    "x = datasets[datasetAtual-1][[\"feature1\", \"feature2\"]].values\n",
    "y = datasets[datasetAtual-1][\"classe\"].values\n",
    "\n",
    "# DEFININDO O RANGE DA TAXA DE APRENDIZAGEM\n",
    "arrayValoresTaxaAprendizagem = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e-0]\n",
    "\n",
    "# ARRAY PARA GUARDAR OS OBJETOS MULTINEURON DE CADA TAXA DE APRENDIZAGEM\n",
    "arrayObjMultiNeuron = []\n",
    "\n",
    "# PARA CADA VALOR DA TAXA DE APRENDIZAGEM\n",
    "for taxaAtual in arrayValoresTaxaAprendizagem:\n",
    "    objMultiNeuron = MultiNeuron(taxaAprendizagem=taxaAtual, qtdMaxEpocas=qtdMaxEpocas, percentualSemMelhora=percentualSemMelhora, armazenarEvolucaoNeuronios=True)\n",
    "    objMultiNeuron.treinar(x, y)\n",
    "    arrayObjMultiNeuron.append(objMultiNeuron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Critério de parada de cada neurônio para cada taxa de aprendizagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "resultado = plotarResultadoTreinamento(arrayValoresTaxaAprendizagem, arrayObjMultiNeuron)\n",
    "resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evolução das acurácias de treinamento e dos pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotarEvolucaoAcuracias(arrayValoresTaxaAprendizagem, arrayObjMultiNeuron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plotarEvolucaoPesos(arrayValoresTaxaAprendizagem, arrayObjMultiNeuron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "## Teste com Olivetti Faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetOlivetti = fetch_olivetti_faces()\n",
    "data            = datasetOlivetti.data\n",
    "target          = datasetOlivetti.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data   = data[0:50]\n",
    "target = target[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# MATRIZ DE ACURACIAS -> CADA LINHA E UM VALOR DE TAXA DE APRENDIZAGEM E CADA COLUNA E UMA INTERACAO DO HOLDOUT\n",
    "matrizAcuracias = []\n",
    "\n",
    "# DEFININDO O RANGE DA TAXA DE APRENDIZAGEM\n",
    "arrayValoresTaxaAprendizagem = [1e-4, 1e-1] #[1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e-0]\n",
    "\n",
    "# PARA CADA VALOR DE TAXA\n",
    "for taxaAtual in arrayValoresTaxaAprendizagem:\n",
    "    \n",
    "    print(\"Iniciando os testes com taxa de\", taxaAtual)\n",
    "    \n",
    "    linhaAcuraciasTaxaAtual = []\n",
    "    \n",
    "    # FACO UM BOOTSTRAP COM H HOLDOUTS\n",
    "    H = 2\n",
    "    for h in range(H):\n",
    "        \n",
    "        # SEPARANDO ENTRE DADOS DE TREINAMENTO E TESTE\n",
    "        xTrain, xTest, yTrain, yTest = tts(data, target, test_size=0.25, shuffle=True)\n",
    "        \n",
    "        # UTILIZANDO A CLASSE CRIADA PARA TREINAR E TESTAR\n",
    "        objMultiNeuron = MultiNeuron(taxaAprendizagem=taxaAtual)\n",
    "        objMultiNeuron.treinar(xTrain, yTrain)\n",
    "        yPred = objMultiNeuron.predizer(xTest)\n",
    "        \n",
    "        # COLOCANDO O RESULTADO NA LINHA DA TAXA ATUAL NA MATRIZ DE ACURACIAS\n",
    "        linhaAcuraciasTaxaAtual.append(accuracy_score(yTest, yPred))\n",
    "        \n",
    "        print(str(100*(h+1)/H) + \"%\")\n",
    "        \n",
    "    # AGORA QUE JA TENHO TODOS OS RESULTADOS DO HOLDOUT PARA A TAXA ATUAL, COLOCO A NOVA LINHA NA MATRIZ\n",
    "    matrizAcuracias.append(linhaAcuraciasTaxaAtual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotarACCxTaxa(arrayValoresTaxaAprendizagem, matrizAcuracias)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
